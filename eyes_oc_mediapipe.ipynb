{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c06fbe",
   "metadata": {},
   "source": [
    "# Open/Closed eyes detector using MediaPipe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80388b9a",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4270b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.lib.video import DisplayPort, VideoMode, PIXEL_RGB\n",
    "import cv2, time, math\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc754f",
   "metadata": {},
   "source": [
    "## Defining camera I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318867b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- I/O ------------------------------------------------------------------\n",
    "Mode = VideoMode(640, 480, 24)\n",
    "dp    = DisplayPort();  dp.configure(Mode, PIXEL_RGB)\n",
    "cap   = cv2.VideoCapture(0 + cv2.CAP_V4L2)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52209909",
   "metadata": {},
   "source": [
    "## Feature extraction definition and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "766623c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FaceMesh -------------------------------------------------------------\n",
    "mp_face  = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(static_image_mode=False,\n",
    "                             max_num_faces=1,\n",
    "                             refine_landmarks=True)  # iris points\n",
    "\n",
    "# Indici dei 6 landmark usati per l’EAR (occhio sinistro)\n",
    "LIND = [33, 160, 158, 133, 153, 144]   # (p1…p6)\n",
    "\n",
    "def ear(pts):\n",
    "    # pts = list of 6 (x,y) pixel tuples\n",
    "    A = math.dist(pts[1], pts[5])\n",
    "    B = math.dist(pts[2], pts[4])\n",
    "    C = math.dist(pts[0], pts[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "THRESH = 0.25       # chiuso se EAR < THRESH\n",
    "INTERVAL = 0.0001    # secondi tra due catture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757a8cc",
   "metadata": {},
   "source": [
    "## Exec loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf1e9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1747498124.239270    6393 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1747498124.312693    6394 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occhi:UNKNOWN\n",
      "Servizio Interrotto\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        t0 = time.time()\n",
    "        # prova a leggere\n",
    "        ret, frame = cap.read()\n",
    "        # se non funziona la telecamera, interrompi\n",
    "        if not ret:  break\n",
    "\n",
    "        # FaceMesh => landmark\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        res = face_mesh.process(rgb)\n",
    "        state = \"UNKNOWN\"\n",
    "        if res.multi_face_landmarks:\n",
    "            lm = res.multi_face_landmarks[0].landmark\n",
    "            h, w = frame.shape[:2]\n",
    "            pts = [(int(lm[i].x * w), int(lm[i].y * h)) for i in LIND]\n",
    "            _ear = ear(pts)\n",
    "            state = \"CHIUSI\" if _ear < THRESH else \"APERTI\"\n",
    "            # disegna una linea sullo schermo\n",
    "            cv2.putText(frame, f\"OCCHI: {state}\", (10,35),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.0,(0,255,0),2)\n",
    "\n",
    "        out = dp.newframe();  out[:] = frame;  dp.writeframe(out)\n",
    "        # Stampa a console (opzionale)\n",
    "        outstring = \"Occhi:\" + str(state)\n",
    "        print(outstring, end=\"\\r\")\n",
    "\n",
    "        # attende fino a INTERVAL s dall’inizio del ciclo\n",
    "        time.sleep(max(0, INTERVAL - (time.time() - t0)))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    cap.release() \n",
    "    dp.stop()\n",
    "    print(\"\\nServizio Interrotto\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
